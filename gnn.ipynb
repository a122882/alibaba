{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('mytrain')\n",
    "df_train['name'] = df_train['first']+df_train['last']+df_train['dob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('mytest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>scale_city_pop</th>\n",
       "      <th>scale_age</th>\n",
       "      <th>scale_state_fe</th>\n",
       "      <th>scale_city_fe</th>\n",
       "      <th>scale_category_fe</th>\n",
       "      <th>scale_job_fe</th>\n",
       "      <th>scale_merchant_fe</th>\n",
       "      <th>scale_zip_fe</th>\n",
       "      <th>scale_amt</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280895</td>\n",
       "      <td>-0.892170</td>\n",
       "      <td>-0.405791</td>\n",
       "      <td>-0.026052</td>\n",
       "      <td>-1.557372</td>\n",
       "      <td>-0.184968</td>\n",
       "      <td>-1.478751</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>-1.336859</td>\n",
       "      <td>JenniferBanks1988-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291960</td>\n",
       "      <td>-0.311130</td>\n",
       "      <td>-0.848021</td>\n",
       "      <td>1.491598</td>\n",
       "      <td>0.976031</td>\n",
       "      <td>0.581454</td>\n",
       "      <td>0.874048</td>\n",
       "      <td>1.541006</td>\n",
       "      <td>0.876702</td>\n",
       "      <td>StephanieGill1978-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278715</td>\n",
       "      <td>0.618533</td>\n",
       "      <td>-1.369674</td>\n",
       "      <td>-1.551706</td>\n",
       "      <td>-0.290420</td>\n",
       "      <td>-1.681313</td>\n",
       "      <td>-0.295716</td>\n",
       "      <td>-1.750851</td>\n",
       "      <td>1.394969</td>\n",
       "      <td>EdwardSanchez1962-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286040</td>\n",
       "      <td>0.328014</td>\n",
       "      <td>-1.127582</td>\n",
       "      <td>-1.561710</td>\n",
       "      <td>1.262023</td>\n",
       "      <td>-0.685558</td>\n",
       "      <td>1.050366</td>\n",
       "      <td>-1.763877</td>\n",
       "      <td>0.250940</td>\n",
       "      <td>JeremyWhite1967-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292125</td>\n",
       "      <td>-0.775962</td>\n",
       "      <td>-0.445406</td>\n",
       "      <td>-0.037057</td>\n",
       "      <td>-0.878387</td>\n",
       "      <td>-0.938566</td>\n",
       "      <td>-0.877754</td>\n",
       "      <td>0.221398</td>\n",
       "      <td>0.200532</td>\n",
       "      <td>TylerGarcia1986-03-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ... scale_city_pop  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...      -0.280895   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...      -0.291960   \n",
       "2      594 White Dale Suite 530      Malad City  ...      -0.278715   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...      -0.286040   \n",
       "4              408 Bradley Rest        Doe Hill  ...      -0.292125   \n",
       "\n",
       "   scale_age  scale_state_fe  scale_city_fe  scale_category_fe scale_job_fe  \\\n",
       "0  -0.892170       -0.405791      -0.026052          -1.557372    -0.184968   \n",
       "1  -0.311130       -0.848021       1.491598           0.976031     0.581454   \n",
       "2   0.618533       -1.369674      -1.551706          -0.290420    -1.681313   \n",
       "3   0.328014       -1.127582      -1.561710           1.262023    -0.685558   \n",
       "4  -0.775962       -0.445406      -0.037057          -0.878387    -0.938566   \n",
       "\n",
       "  scale_merchant_fe scale_zip_fe  scale_amt                     name  \n",
       "0         -1.478751     0.235727  -1.336859  JenniferBanks1988-03-09  \n",
       "1          0.874048     1.541006   0.876702  StephanieGill1978-06-21  \n",
       "2         -0.295716    -1.750851   1.394969  EdwardSanchez1962-01-19  \n",
       "3          1.050366    -1.763877   0.250940    JeremyWhite1967-01-12  \n",
       "4         -0.877754     0.221398   0.200532    TylerGarcia1986-03-28  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if one person how many cards. one person one card but many transaction\n",
    "\n",
    "install torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df_train, stratify=df_train['is_fraud'], train_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nam = df_train.name.unique()\\nn= 0\\nfor m in nam:\\n    df = df_train.loc[df_train['name'] == m]\\n    if df.cc_num.nunique() > 1:\\n        n+= 1\\nprint(n)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''nam = df_train.name.unique()\n",
    "n= 0\n",
    "for m in nam:\n",
    "    df = df_train.loc[df_train['name'] == m]\n",
    "    if df.cc_num.nunique() > 1:\n",
    "        n+= 1\n",
    "print(n)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data.storage import BaseStorage, NodeStorage, EdgeStorage\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.groupby('cc_num')\n",
    "#df_train = df_train.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.CountEncoder(cols=\"cc_num\", normalize=True)\n",
    "df_train[\"cc_num1\"] = encoder.fit_transform(df_train[\"cc_num\"])\n",
    "df_test[\"cc_num1\"] = encoder.transform(df_test[\"cc_num\"])\n",
    "encoder = ce.CountEncoder(cols=\"trans_num\", normalize=True)\n",
    "df_train[\"trans_num1\"] = encoder.fit_transform(df_train[\"trans_num\"])\n",
    "df_test[\"trans_num1\"] = encoder.transform(df_test[\"trans_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cc_num'].x = df_train.cc_num\n",
    "data['cos_time'].x = df_train.trans_hour_cos\n",
    "data['sin_time'].x = df_train.trans_hour_sin\n",
    "data['amt'].x = df_train.scale_amt\n",
    "data['merchant'].x = df_train.merchant_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"G = nx.DiGraph()\\nG.add_nodes_from(df_train['cc_num1'].unique(), type = 'cc_num1')\\nG.add_nodes_from(df_train['merchant_fe'].unique(), type = 'merchant_fe')\\nG.add_nodes_from(df_train['trans_num1'], type = 'trans_num1')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''G = nx.DiGraph()\n",
    "G.add_nodes_from(df_train['cc_num1'].unique(), type = 'cc_num1')\n",
    "G.add_nodes_from(df_train['merchant_fe'].unique(), type = 'merchant_fe')\n",
    "G.add_nodes_from(df_train['trans_num1'], type = 'trans_num1')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a = df_train.drop_duplicates(subset='name')\\nfor _, row in a.iterrows():\\n    scale_age = row['scale_age']\\n    scale_job_fe = row['scale_job_fe']\\n    attrs = {row['cc_num1']:{'scale_age': scale_age, 'scale_job_fe': scale_job_fe}}\\n    nx.set_node_attributes(G, attrs)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''a = df_train.drop_duplicates(subset='name')\n",
    "for _, row in a.iterrows():\n",
    "    scale_age = row['scale_age']\n",
    "    scale_job_fe = row['scale_job_fe']\n",
    "    attrs = {row['cc_num1']:{'scale_age': scale_age, 'scale_job_fe': scale_job_fe}}\n",
    "    nx.set_node_attributes(G, attrs)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for _, row in df_train.iterrows():\\n  scale_amt = row['scale_amt']\\n  trans_hour_sin = row['trans_hour_sin']\\n  trans_hour_cos = row['trans_hour_cos']\\n  scale_state_fe = row['scale_state_fe']\\n  scale_category_fe = row['scale_category_fe']\\n  is_fraud = row['is_fraud']\\n  attrs = {row['trans_num']:{'scale_amt' : scale_amt,\\n                              'trans_hour_sin' : trans_hour_sin,\\n                              'trans_hour_cos' : trans_hour_cos,\\n                              'scale_state_fe' : scale_state_fe,\\n                              'scale_category_fe' : scale_category_fe}}\\n  nx.set_node_attributes(G, attrs)\\n  G.add_edge(row['cc_num1'], row['trans_num1'])\\n  G.add_edge(row['trans_num1'], row['merchant_fe'])\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for _, row in df_train.iterrows():\n",
    "  scale_amt = row['scale_amt']\n",
    "  trans_hour_sin = row['trans_hour_sin']\n",
    "  trans_hour_cos = row['trans_hour_cos']\n",
    "  scale_state_fe = row['scale_state_fe']\n",
    "  scale_category_fe = row['scale_category_fe']\n",
    "  is_fraud = row['is_fraud']\n",
    "  attrs = {row['trans_num']:{'scale_amt' : scale_amt,\n",
    "                              'trans_hour_sin' : trans_hour_sin,\n",
    "                              'trans_hour_cos' : trans_hour_cos,\n",
    "                              'scale_state_fe' : scale_state_fe,\n",
    "                              'scale_category_fe' : scale_category_fe}}\n",
    "  nx.set_node_attributes(G, attrs)\n",
    "  G.add_edge(row['cc_num1'], row['trans_num1'])\n",
    "  G.add_edge(row['trans_num1'], row['merchant_fe'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"k = []\\nfor i in range(1000):\\n    a = df_train['cc_num'][i]\\n    b = df_train['merchant'][i]\\n    c = df_train['trans_num'][i]\\n    k.append(a)\\n    k.append(b)\\n    k.append(c)\\nnx.spring_layout(G.subgraph(k))\\npos = nx.spring_layout(G.subgraph(k), scale=20, k=3/np.sqrt(G.subgraph(k).order()))\\nd = dict(G.subgraph(k).degree)\\nnx.draw(G.subgraph(k), pos, \\n        nodelist=d, \\n        node_size=[d[k]*30 for k in d])\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''k = []\n",
    "for i in range(1000):\n",
    "    a = df_train['cc_num'][i]\n",
    "    b = df_train['merchant'][i]\n",
    "    c = df_train['trans_num'][i]\n",
    "    k.append(a)\n",
    "    k.append(b)\n",
    "    k.append(c)\n",
    "nx.spring_layout(G.subgraph(k))\n",
    "pos = nx.spring_layout(G.subgraph(k), scale=20, k=3/np.sqrt(G.subgraph(k).order()))\n",
    "d = dict(G.subgraph(k).degree)\n",
    "nx.draw(G.subgraph(k), pos, \n",
    "        nodelist=d, \n",
    "        node_size=[d[k]*30 for k in d])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_train.drop_duplicates(subset='name')\n",
    "pos_dict_cc = {}\n",
    "i = 0\n",
    "for _, row in a.iterrows():\n",
    "    pos_dict_cc[row['cc_num']] = i\n",
    "    i+=1\n",
    "b = df_train.drop_duplicates(subset='merchant')\n",
    "pos_dict_merchant = {}\n",
    "ii = 0\n",
    "for _ , row in b.iterrows():\n",
    "    pos_dict_merchant[row['merchant']] = ii\n",
    "    ii += 1\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "iii=0\n",
    "for _, row in df_train.iterrows():\n",
    "    list1.append(pos_dict_cc[row['cc_num']])\n",
    "    list2.append(iii)\n",
    "    list3.append(pos_dict_merchant[row['merchant']])\n",
    "    iii+=1\n",
    "    \n",
    "edge_cc = torch.tensor([list1, list2])\n",
    "edge_merchant = torch.tensor([list2, list3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = df_train.drop_duplicates(subset='name')\n",
    "pos_dict_cc = {}\n",
    "i = 0\n",
    "for _, row in a.iterrows():\n",
    "    pos_dict_cc[row['cc_num1']] = i\n",
    "    i+=1\n",
    "b = df_train.drop_duplicates(subset='merchant')\n",
    "pos_dict_merchant = {}\n",
    "ii = 0\n",
    "for _ , row in b.iterrows():\n",
    "    pos_dict_merchant[row['merchant']] = ii\n",
    "    ii += 1\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "iii=0\n",
    "for _, row in df_train.iterrows():\n",
    "    list1.append(pos_dict_cc[row['cc_num1']])\n",
    "    list2.append(iii)\n",
    "    list3.append(pos_dict_merchant[row['merchant']])\n",
    "    iii+=1\n",
    "    \n",
    "edge_cc = torch.tensor([list1, list2])\n",
    "edge_merchant = torch.tensor([list2, list3])\n",
    "def df_to_tensor(x: pd.DataFrame):\n",
    "    return torch.from_numpy(x.values).to(torch.device('cpu'),dtype=torch.float)\n",
    "\n",
    "dictionary = dict({'cc_num1':0,'scale_age':1,'scale_job_fe':2,'trans_num1':3,'trans_hour_cos':4,'trans_hour_sin':5,'scale_amt':6,'scale_category_fe':7, 'scale_state_fe':8,'merchant_fe':9})\n",
    "df_cc_num = a[['scale_age','scale_job_fe']]\n",
    "df_trans_num = df_train[['trans_hour_cos','trans_hour_sin','scale_amt','scale_category_fe', 'scale_state_fe']]\n",
    "df_merchant = b[['merchant_fe']]\n",
    "tensor_cc_num = df_to_tensor(df_cc_num)\n",
    "tensor_tran_num = df_to_tensor(df_trans_num)\n",
    "tensor_merchant = df_to_tensor(df_merchant)\n",
    "\n",
    "data = HeteroData()\n",
    "data['cc'].x = tensor_cc_num\n",
    "data['trans'].x = tensor_tran_num\n",
    "data['merchant'].x = tensor_merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['cc','pay','trans'].edge_index = edge_cc\n",
    "data['trans', 'obtain', 'merchant'].edge_index = edge_merchant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  \u001b[1mcc\u001b[0m={ x=[976, 2] },\n",
       "  \u001b[1mtrans\u001b[0m={ x=[641489, 5] },\n",
       "  \u001b[1mmerchant\u001b[0m={ x=[693, 1] },\n",
       "  \u001b[1m(cc, pay, trans)\u001b[0m={ edge_index=[2, 641489] },\n",
       "  \u001b[1m(trans, obtain, merchant)\u001b[0m={ edge_index=[2, 641489] }\n",
       ")>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"user_dict = {}\\nfor _, row in df_train.iterrows():\\n    cc = row['cc_num1']\\n    k = user_dict.get(cc)\\n    if k is None:\\n        user_dict[cc] = row['is_fraud']\\n        continue\\n    if k == 0:\\n        user_dict[cc] = row['is_fraud']\\nlist5 = []\\nfor \""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''user_dict = {}\n",
    "for _, row in df_train.iterrows():\n",
    "    cc = row['cc_num1']\n",
    "    k = user_dict.get(cc)\n",
    "    if k is None:\n",
    "        user_dict[cc] = row['is_fraud']\n",
    "        continue\n",
    "    if k == 0:\n",
    "        user_dict[cc] = row['is_fraud']\n",
    "list5 = []\n",
    "for '''\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_to_tensor(df_train[['is_fraud']]).tolist()\n",
    "data['trans'].y = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  \u001b[1mcc\u001b[0m={ x=[976, 2] },\n",
       "  \u001b[1mtrans\u001b[0m={\n",
       "    x=[641489, 5],\n",
       "    y=[641489]\n",
       "  },\n",
       "  \u001b[1mmerchant\u001b[0m={ x=[693, 1] },\n",
       "  \u001b[1m(cc, pay, trans)\u001b[0m={ edge_index=[2, 641489] },\n",
       "  \u001b[1m(trans, obtain, merchant)\u001b[0m={ edge_index=[2, 641489] }\n",
       ")>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "data = T.ToUndirected()(data)\n",
    "data = T.NormalizeFeatures()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mcc\u001b[0m={ x=[976, 2] },\n",
       "  \u001b[1mtrans\u001b[0m={\n",
       "    x=[641489, 5],\n",
       "    y=[641489],\n",
       "    train_mask=[641489],\n",
       "    val_mask=[641489],\n",
       "    test_mask=[641489]\n",
       "  },\n",
       "  \u001b[1mmerchant\u001b[0m={ x=[693, 1] },\n",
       "  \u001b[1m(cc, pay, trans)\u001b[0m={ edge_index=[2, 641489] },\n",
       "  \u001b[1m(trans, obtain, merchant)\u001b[0m={ edge_index=[2, 641489] },\n",
       "  \u001b[1m(trans, rev_pay, cc)\u001b[0m={ edge_index=[2, 641489] },\n",
       "  \u001b[1m(merchant, rev_obtain, trans)\u001b[0m={ edge_index=[2, 641489] }\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = T.RandomNodeSplit(split='train_rest')(data)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden, out):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1,-1), hidden)\n",
    "        self.conv2 = SAGEConv((-1,-1), out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index)) \n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "model = GNN(hidden= 64, out= 2)\n",
    "model = to_hetero(model, data1.metadata(), aggr= 'sum')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList\n",
    "from torch_geometric.nn import Linear, SAGEConv\n",
    "\n",
    "def weighted_cross_entropy(out, target, mask=None, weight=None):\n",
    "    loss = F.cross_entropy(out, target, reduction=\"none\")\n",
    "\n",
    "    if weight is not None:\n",
    "        weight = target * weight[1] + (1 - target) * weight[0]\n",
    "        weight *= mask\n",
    "        weight *= mask.sum() / weight.sum()\n",
    "        loss *= weight\n",
    "\n",
    "    loss *= mask\n",
    "    loss = loss.sum() / mask.sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "'''class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers):\n",
    "        super().__init__()\n",
    "        assert num_layers > 1\n",
    "        self.convs = ModuleList([SAGEConv((-1, -1), hidden_channels) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != len(self.convs) - 1:\n",
    "                x = F.relu(x)\n",
    "        return x'''\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hetero_gnn,\n",
    "        embedding_size,\n",
    "        out_channels,\n",
    "        node_types,\n",
    "        num_nodes_per_type,\n",
    "        class_weight=None,\n",
    "        full_batch=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hetero_gnn = hetero_gnn\n",
    "        self.embedding = nn.ModuleDict(\n",
    "            {\n",
    "                node_type: nn.Embedding(num_nodes_per_type[node_type], embedding_size)\n",
    "                for node_type in node_types\n",
    "                if node_type != \"trans\"\n",
    "            }\n",
    "        )\n",
    "        self.linear = Linear(-1, out_channels)\n",
    "        self.node_types = node_types\n",
    "        self.full_batch = full_batch\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, batch_size=None, n_id_dict=None, target=None, mask=None):\n",
    "        for node_type in self.node_types:\n",
    "            if node_type != \"trans\":\n",
    "                if self.full_batch:\n",
    "                    x_dict[node_type] = self.embedding[node_type]\n",
    "                else:\n",
    "                    assert n_id_dict is not None, \"If using a sampled batch, `n_id_dict` must be provided.\"\n",
    "                    x_dict[node_type] = self.embedding[node_type](n_id_dict[node_type])\n",
    "\n",
    "        x_dict = self.hetero_gnn(x_dict, edge_index_dict)\n",
    "        out = self.linear(x_dict[\"trans\"])\n",
    "        if self.training:\n",
    "            if not self.full_batch:\n",
    "                assert batch_size is not None, \"If using a sampled batch, `batch_size` must be provided.\"\n",
    "                mask = (target * 0).bool()\n",
    "                mask[:batch_size] = 1\n",
    "            loss = weighted_cross_entropy(out, target, mask, self.class_weight)\n",
    "            return out, loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(data1.x_dict, data1.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fv/8hm4vw413xldkj_p_9vw0kgw0000gn/T/ipykernel_91272/1373247601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "from poptorch_geometric import FixedSizeOptions\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "fixed_size_options = FixedSizeOptions.from_loader(train_loader)\n",
    "fixed_size_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fv/8hm4vw413xldkj_p_9vw0kgw0000gn/T/ipykernel_91272/3358423264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcolour_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_homogeneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspring_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Split the nodes by node type and add some randomness to separate the nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_spring_layout_1\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/drawing/layout.py\u001b[0m in \u001b[0;36mspring_layout\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mnnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdom_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         pos = _sparse_fruchterman_reingold(\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap__sparse_fruchterman_reingold_5\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/drawing/layout.py\u001b[0m in \u001b[0;36m_sparse_fruchterman_reingold\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# distance between points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0;31m# enforce minimum distance of 0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Convert to homogeneous\n",
    "data_homogeneous = data.to_homogeneous()\n",
    "g = to_networkx(data_homogeneous)\n",
    "# Use node types as colour map\n",
    "colour_map = data_homogeneous.node_type\n",
    "\n",
    "pos = nx.spring_layout(g)\n",
    "\n",
    "# Split the nodes by node type and add some randomness to separate the nodes\n",
    "for i in range(0, len(colour_map)):\n",
    "    if colour_map[i] != 0:\n",
    "        pos[i][0] += np.cos(colour_map[i] / 2) * 10 + random.randint(-1, 1)\n",
    "        pos[i][1] += np.sin(colour_map[i] / 2) * 10 + random.randint(-1, 1)\n",
    "    else:\n",
    "        pos[i][0] += random.randint(-3, 3)\n",
    "        pos[i][1] += random.randint(-3, 3)\n",
    "\n",
    "nx.draw_networkx(g, pos=pos, node_color=colour_map * 40, cmap=plt.cm.tab20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fv/8hm4vw413xldkj_p_9vw0kgw0000gn/T/ipykernel_91272/2924265350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fv/8hm4vw413xldkj_p_9vw0kgw0000gn/T/ipykernel_91272/2924265350.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['trans'].train_mask\n",
    "    loss = F.cross_entropy(out['trans'][mask], data['trans'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
